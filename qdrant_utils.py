import gc
import torch
import re
from typing import List, Tuple, Dict, Set
from concurrent.futures import ThreadPoolExecutor
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.models import MatchValue, MatchAny, Filter, FieldCondition
from sklearn.metrics.pairwise import cosine_similarity

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… Qdrant ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
qdrant_client = QdrantClient(host="localhost", port=6333)
collection_name = "retailtech_test"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… SentenceTransformer (KURE_v1) â†’ CPU ê°•ì œ ì‚¬ìš©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model = SentenceTransformer("nlpai-lab/KURE-v1", device="cpu")

def encode_and_clear(texts, **kwargs):
    """CPUì—ì„œë§Œ ì„ë² ë”© ìˆ˜í–‰ (GPU ì™„ì „ ë¹„í™œì„±)"""
    vectors = model.encode(texts, device="cpu", **kwargs)
    gc.collect()
    return vectors


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… ê³µí†µ ì ìˆ˜ ë³´ì • í•¨ìˆ˜ (RetailTech ì¶œë ¥ í¬ë§·)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def apply_keyword_bonus(results, text_keywords, top_k):
    """ê²€ìƒ‰ ê²°ê³¼ì— í‚¤ì›Œë“œ êµì§‘í•© ê¸°ë°˜ ì ìˆ˜ ë³´ë„ˆìŠ¤ ì ìš© + RetailTech ìŠ¤íƒ€ì¼ ì¶œë ¥"""
    reranked = []
    for i, hit in enumerate(results, 1):
        payload = hit.payload
        score = float(hit.score)
        doc_keywords = payload.get("keywords", [])

        matched_keywords = []
        for kw in text_keywords:
            if kw in (payload.get("sFileName") or "") or kw in doc_keywords:
                matched_keywords.append(kw)

        # âœ… í‚¤ì›Œë“œ ë§¤ì¹­ ì‹œ ì ìˆ˜ ë³´ì •
     #   for j, _ in enumerate(matched_keywords):
     #       score += max(0.05 - j * 0.01, 0.01)

        # ğŸ”¹ í•„ë“œ ì¶”ì¶œ
        record_id = payload.get("record_id", "ì—†ìŒ")
        store_name = payload.get("store_name", "ì í¬ëª… ì—†ìŒ")
        store_code = payload.get("store_code", "ì½”ë“œ ì—†ìŒ")
        title = payload.get("title", "ì œëª© ì—†ìŒ")
        text = payload.get("text", "ë‚´ìš© ì—†ìŒ")

        fault_major = payload.get("fault_major", "-")
        fault_mid = payload.get("fault_mid", "-")
        fault_minor = payload.get("fault_minor", "-")
        urgency = payload.get("urgency", "-")
        department_main = payload.get("department_main", "-")
        progress = payload.get("progress", "-")
        elapsed_time = payload.get("elapsed_time", "0")
        ocs_major = payload.get("ocs_cause_major", "-")
        ocs_mid = payload.get("ocs_cause_mid", "-")
        ocs_minor = payload.get("ocs_cause_minor", "-")

        keywords = payload.get("keywords", [])
        keywords_str = ", ".join(keywords) if keywords else "ì—†ìŒ"

        year = payload.get("year", "")
        month = str(payload.get("month", "")).zfill(2)
        day = str(payload.get("day", "")).zfill(2)
        date_str = f"{year}-{month}-{day}" if year and month and day else "ë‚ ì§œ ì •ë³´ ì—†ìŒ"

        # ğŸ”¹ ì½˜ì†” ì¶œë ¥
        print(f"ğŸ”¹ ê²°ê³¼ {i}")
        print(f"ğŸ†” ì ‘ìˆ˜ë²ˆí˜¸: {record_id}")
        print(f"ğŸª ì í¬ëª…: {store_name} ({store_code})")
        print(f"ğŸ“… ë‚ ì§œ: {date_str}")
        print(f"ğŸ•“ ê²½ê³¼ì‹œê°„: {elapsed_time}ì‹œê°„ / ê¸´ê¸‰ë„: {urgency}")
        print(f"ğŸ§© ì¥ì• ìœ í˜•: {fault_major} > {fault_mid} > {fault_minor}")
        print(f"âš™ï¸ OCS ì›ì¸: {ocs_major} > {ocs_mid} > {ocs_minor}")
        print(f"ğŸ¢ ì²˜ë¦¬ë¶€ì„œ: {department_main}")
        print(f"ğŸ“‹ ì§„í–‰ë‹¨ê³„: {progress}")
        print(f"ğŸ— í‚¤ì›Œë“œ: {keywords_str}")
        print(f"ğŸ§  ìœ ì‚¬ë„ ì ìˆ˜: {round(score, 5)}")
        print(f"ğŸ“ ì œëª©: {title}")
        print(f"ğŸ’¬ ë‚´ìš©: {text[:250]}{'...' if len(text) > 250 else ''}")
        print("â”€â”€â”€â”€" * 10)

        reranked.append({
            "id": hit.id,
            "record_id": record_id,
            "store_name": store_name,
            "store_code": store_code,
            "date": date_str,
            "fault_major": fault_major,
            "fault_mid": fault_mid,
            "fault_minor": fault_minor,
            "urgency": urgency,
            "department_main": department_main,
            "progress": progress,
            "ocs_cause_major": ocs_major,
            "ocs_cause_mid": ocs_mid,
            "ocs_cause_minor": ocs_minor,
            "keywords": keywords_str,
            "title": title,
            "text": text,
            "score": round(score, 5),
        })

    print("\nğŸ¯ ê²€ìƒ‰ ì™„ë£Œ. ìƒìœ„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
    reranked.sort(key=lambda x: x["score"], reverse=True)
    return reranked[:top_k]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… ë‹¨ì¼ í‚¤ì›Œë“œ ê²€ìƒ‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def keyword_search_single(keyword: str, top_k: int = 30) -> Tuple[Set, Dict, str]:
    keyword_type = "none"
    query_filter = None

    if re.fullmatch(r"\d{4}", keyword):  # ì—°ë„
        keyword_type = "year"
        query_filter = Filter(must=[
            FieldCondition(key="year", match=MatchValue(value=int(keyword)))
        ])
    elif keyword.isdigit() and 1 <= int(keyword) <= 12:  # ì›”
        keyword_type = "month"
        query_filter = Filter(must=[
            FieldCondition(key="month", match=MatchValue(value=int(keyword)))
        ])
    elif keyword.isdigit() and 1 <= int(keyword) <= 31:  # ì¼
        keyword_type = "day"
        query_filter = Filter(must=[
            FieldCondition(key="day", match=MatchValue(value=int(keyword)))
        ])
    else:  # í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ
        keyword_type = "text"
        query_filter = Filter(should=[
            FieldCondition(key="sFileName", match=MatchValue(value=keyword)),
            FieldCondition(key="keywords", match=MatchAny(any=[keyword])),
            FieldCondition(key="store_name", match=MatchValue(value=keyword)),  # âœ… ì í¬ëª… ê²€ìƒ‰
            FieldCondition(key="store_code", match=MatchValue(value=keyword)),  # âœ… ì í¬ì½”ë“œ ê²€ìƒ‰
        ])

    result = qdrant_client.query_points(
        collection_name=collection_name,
        query_filter=query_filter,
        limit=top_k,
        with_payload=True,
        with_vectors=True,
    )

    ids = {p.id for p in result.points}
    payloads = {p.id: {"payload": p.payload, "vector": p.vector} for p in result.points}

    return ids, payloads, keyword_type



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… ë³‘ë ¬ í‚¤ì›Œë“œ ê²€ìƒ‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def search_qdrant_metadata_parallel(keywords: List[str], top_k_per_keyword: int = 50) -> Tuple[Dict, Dict, Dict]:
    all_payloads = {}
    keyword_results = {}
    keyword_types = {}

    if not keywords:
        return {}, {}, {}

    with ThreadPoolExecutor(max_workers=max(1, len(keywords))) as executor:
        futures = {executor.submit(keyword_search_single, kw, top_k_per_keyword): kw for kw in keywords}
        for future in futures:
            ids, payloads, kw_type = future.result()
            kw = futures[future]
            keyword_results[kw] = ids
            keyword_types[kw] = kw_type
            all_payloads.update(payloads)

    return keyword_results, all_payloads, keyword_types


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… ë‚ ì§œ + í‚¤ì›Œë“œ ê²°í•© ê²€ìƒ‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def keyword_then_semantic_rerank(question: str, keywords: List[str], top_k: int = 5):
    print("\n" + "=" * 80)
    print(f"ğŸ§© [keyword_then_semantic_rerank] ê²€ìƒ‰ ìš”ì²­ ì‹œì‘")
    print(f"ğŸ“¥ ì§ˆë¬¸: {question}")
    print(f"ğŸ”‘ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸: {keywords}")
    print("=" * 80)

    keyword_results, all_payloads, keyword_types = search_qdrant_metadata_parallel(keywords, top_k_per_keyword=200)
    date_keywords = [kw for kw, t in keyword_types.items() if t in ("year", "month", "day")]
    text_keywords = [kw for kw, t in keyword_types.items() if t == "text"]

    print(f"ğŸ“… ë‚ ì§œ í‚¤ì›Œë“œ: {date_keywords if date_keywords else 'ì—†ìŒ'}")
    print(f"ğŸ’¬ í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ: {text_keywords if text_keywords else 'ì—†ìŒ'}")

    # ë‚ ì§œê°€ í¬í•¨ëœ ê²½ìš°
    if date_keywords:
        print("\nâš¡ [1ë‹¨ê³„] ë‚ ì§œ + í‚¤ì›Œë“œ ê²°í•© â†’ Qdrant ê²€ìƒ‰ ì‹¤í–‰")
        query_vector = encode_and_clear([question])[0]

        must_conditions = []
        for kw in date_keywords:
            kw_type = keyword_types[kw]
            if kw_type == "year":
                must_conditions.append(FieldCondition(key="year", match=MatchValue(value=int(kw))))
            elif kw_type == "month":
                must_conditions.append(FieldCondition(key="month", match=MatchValue(value=int(kw))))
            elif kw_type == "day":
                must_conditions.append(FieldCondition(key="day", match=MatchValue(value=int(kw))))

        if text_keywords:
            should_conditions = []
            for kw in text_keywords:
                should_conditions.extend([
                    FieldCondition(key="sFileName", match=MatchValue(value=kw)),
                    FieldCondition(key="keywords", match=MatchAny(any=[kw])),
                    FieldCondition(key="keywords", match={"text": kw}),
                ])
            must_conditions.append(Filter(should=should_conditions))

        filter_query = Filter(must=must_conditions)
        results = qdrant_client.search(
            collection_name=collection_name,
            query_vector=query_vector,
            query_filter=filter_query,
            limit=top_k * 10,
            with_payload=True
        )

        if not results:
            print("âš ï¸ [1ë‹¨ê³„] ê²€ìƒ‰ ê²°ê³¼ 0ê±´ â†’ ì˜ë¯¸ê²€ìƒ‰ fallback ì‹¤í–‰")
            return semantic_vector_search(question, top_k)

        return apply_keyword_bonus(results, text_keywords, top_k)

    # í‚¤ì›Œë“œë§Œ ìˆì„ ê²½ìš°
    elif text_keywords:
        print("\nğŸ”¤ [2ë‹¨ê³„] í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ì‹¤í–‰")
        query_vector = encode_and_clear([question])[0]
        should_conditions = []
        for kw in text_keywords:
            should_conditions.extend([
                FieldCondition(key="sFileName", match=MatchValue(value=kw)),
                FieldCondition(key="keywords", match=MatchAny(any=[kw])),
                FieldCondition(key="keywords", match={"text": kw}),
            ])
        filter_query = Filter(should=should_conditions)
        results = qdrant_client.search(
            collection_name=collection_name,
            query_vector=query_vector,
            query_filter=filter_query,
            limit=top_k * 10,
            with_payload=True
        )

        if not results:
            print("âš ï¸ [2ë‹¨ê³„] ê²€ìƒ‰ ê²°ê³¼ 0ê±´ â†’ ì˜ë¯¸ê²€ìƒ‰ fallback ì‹¤í–‰")
            return semantic_vector_search(question, top_k)

        return apply_keyword_bonus(results, text_keywords, top_k)

    # ì•„ë¬´ê²ƒë„ ì—†ì„ ê²½ìš° â†’ ì˜ë¯¸ê²€ìƒ‰ fallback
    else:
        print("\nâš ï¸ [3ë‹¨ê³„] í•„í„° ì—†ìŒ â†’ ì „ì²´ ì˜ë¯¸ê²€ìƒ‰ fallback")
        results = qdrant_client.search(
            collection_name=collection_name,
            query_vector=encode_and_clear([question])[0],
            limit=top_k * 10,
            with_payload=True
        )
        return apply_keyword_bonus(results, keywords, top_k)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… ì˜ë¯¸ê²€ìƒ‰ fallback (ë‹¨ìˆœ ë²¡í„°ê²€ìƒ‰)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def semantic_vector_search(question: str, top_k: int = 30):
    print("\nâš™ï¸ [ë‹¨ìˆœ ì˜ë¯¸ê²€ìƒ‰ fallback] ì‹¤í–‰ ì¤‘...")
    query_vector = encode_and_clear([question])[0]
    results = qdrant_client.search(
        collection_name=collection_name,
        query_vector=query_vector,
        limit=top_k,
        with_payload=True
    )

    reranked = []
    for i, hit in enumerate(results, 1):
        payload = hit.payload
        score = round(float(hit.score), 5)

        record_id = payload.get("record_id", "ì—†ìŒ")
        store_name = payload.get("store_name", "ì í¬ëª… ì—†ìŒ")
        store_code = payload.get("store_code", "ì½”ë“œ ì—†ìŒ")
        title = payload.get("title", "ì œëª© ì—†ìŒ")
        text = payload.get("text", "ë‚´ìš© ì—†ìŒ")

        fault_major = payload.get("fault_major", "-")
        fault_mid = payload.get("fault_mid", "-")
        fault_minor = payload.get("fault_minor", "-")
        urgency = payload.get("urgency", "-")
        department_main = payload.get("department_main", "-")
        progress = payload.get("progress", "-")
        elapsed_time = payload.get("elapsed_time", "0")
        ocs_major = payload.get("ocs_cause_major", "-")
        ocs_mid = payload.get("ocs_cause_mid", "-")
        ocs_minor = payload.get("ocs_cause_minor", "-")

        keywords = payload.get("keywords", [])
        keywords_str = ", ".join(keywords) if keywords else "ì—†ìŒ"

        year = payload.get("year", "")
        month = str(payload.get("month", "")).zfill(2)
        day = str(payload.get("day", "")).zfill(2)
        date_str = f"{year}-{month}-{day}" if year and month and day else "ë‚ ì§œ ì •ë³´ ì—†ìŒ"

        # ì½˜ì†” ì¶œë ¥ (apply_keyword_bonusì™€ ë™ì¼)
        print(f"ğŸ”¹ ê²°ê³¼ {i}")
        print(f"ğŸ†” ì ‘ìˆ˜ë²ˆí˜¸: {record_id}")
        print(f"ğŸª ì í¬ëª…: {store_name} ({store_code})")
        print(f"ğŸ“… ë‚ ì§œ: {date_str}")
        print(f"ğŸ•“ ê²½ê³¼ì‹œê°„: {elapsed_time}ì‹œê°„ / ê¸´ê¸‰ë„: {urgency}")
        print(f"ğŸ§© ì¥ì• ìœ í˜•: {fault_major} > {fault_mid} > {fault_minor}")
        print(f"âš™ï¸ OCS ì›ì¸: {ocs_major} > {ocs_mid} > {ocs_minor}")
        print(f"ğŸ¢ ì²˜ë¦¬ë¶€ì„œ: {department_main}")
        print(f"ğŸ“‹ ì§„í–‰ë‹¨ê³„: {progress}")
        print(f"ğŸ— í‚¤ì›Œë“œ: {keywords_str}")
        print(f"ğŸ§  ìœ ì‚¬ë„ ì ìˆ˜: {score}")
        print(f"ğŸ“ ì œëª©: {title}")
        print(f"ğŸ’¬ ë‚´ìš©: {text[:250]}{'...' if len(text) > 250 else ''}")
        print("â”€â”€â”€â”€" * 10)

        reranked.append({
            "id": hit.id,
            "record_id": record_id,
            "store_name": store_name,
            "store_code": store_code,
            "date": date_str,
            "fault_major": fault_major,
            "fault_mid": fault_mid,
            "fault_minor": fault_minor,
            "urgency": urgency,
            "department_main": department_main,
            "progress": progress,
            "ocs_cause_major": ocs_major,
            "ocs_cause_mid": ocs_mid,
            "ocs_cause_minor": ocs_minor,
            "keywords": keywords_str,
            "title": title,
            "text": text,
            "score": score,
        })

    print("\nğŸ¯ ì˜ë¯¸ê²€ìƒ‰ ì™„ë£Œ. ìƒìœ„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
    return reranked
