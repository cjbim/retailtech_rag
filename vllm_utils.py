import requests
import re

# âœ… vLLM API ì„œë²„ ì •ë³´
VLLM_API_URL = "http://localhost:8000/v1/completions"
MODEL_ID = "/home/filadmin/ai-project/vllm/production-models/gemma-3-27b-it"

# âœ… 1ï¸âƒ£ vLLM API í˜¸ì¶œ í•¨ìˆ˜
def call_vllm(prompt, max_tokens=256, stop=None):
    try:
        response = requests.post(
            VLLM_API_URL,
            headers={"Content-Type": "application/json"},
            json={
                "model": MODEL_ID,
                "prompt": prompt.strip(),
                "max_tokens": max_tokens,
                "temperature": 0.4,
                **({"stop": stop} if stop else {})
            },
            timeout=30
        )

        response.raise_for_status()
        result = response.json()
        print("ğŸ” vLLM ì‘ë‹µ ì „ì²´:", result)

        choices = result.get("choices", [])
        if choices and "text" in choices[0]:
            return choices[0].get("text", "").strip()

        return "[âš ï¸ LLM ì‘ë‹µì— í…ìŠ¤íŠ¸ ì—†ìŒ]"

    except requests.RequestException as e:
        print(f"[âŒ vLLM í˜¸ì¶œ ì‹¤íŒ¨]: {e}")
        return "[âŒ LLM ì„œë²„ ì—°ê²° ì‹¤íŒ¨]"


# âœ… 2ï¸âƒ£ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„± í•¨ìˆ˜
def call_vllm_generate_search_condition(user_question):
    prompt = f"""
ë‹¤ìŒì€ ë¬¸ì„œ ê²€ìƒ‰ìš© í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ëŠ” ì‘ì—…ì´ì•¼.
â—ï¸ì ˆëŒ€ ì„¤ëª…í•˜ì§€ ë§ê³ , ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í‚¤ì›Œë“œ ëª©ë¡ë§Œ ìƒì„±í•´.

ê·œì¹™:
- ì§ˆë¬¸ì— ëª…ì‹œëœ ì—°ë„ê°€ ìˆì„ ë•Œë§Œ í¬í•¨í•´. ì—†ìœ¼ë©´ ì—°ë„ëŠ” ì ˆëŒ€ ë„£ì§€ ë§ˆ.
- ì—°ë„ëŠ” í•­ìƒ 4ìë¦¬ ìˆ«ì (ì˜ˆ: '23ë…„ë„' â†’ '2023')
- ì›”,ì¼ì´ ë“¤ì–´ê°€ë©´ ì•ì— ìˆ«ìë§Œ ì¶”ì¶œí•´ì¤˜
- HTML íƒœê·¸, íŠ¹ìˆ˜ë¬¸ì, ê°œí–‰ë¬¸ì(\\n), ë”°ì˜´í‘œ ë“±ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ
- ì¶œë ¥ì€ ì˜ˆ: í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3 í˜•ì‹ì´ì–´ì•¼ í•¨

ì§ˆë¬¸: {user_question}

í‚¤ì›Œë“œ:"""
    return call_vllm(prompt, max_tokens=32, stop=["\n"])


# âœ… 3ï¸âƒ£ í‚¤ì›Œë“œ í›„ì²˜ë¦¬ í•¨ìˆ˜
def clean_llm_keywords(raw_text: str) -> list:
    first_line = raw_text.strip().split("\n")[0]  # ì²« ì¤„ë§Œ ì‚¬ìš©
    cleaned = re.sub(r"(?i)ì§ˆë¬¸\s*:.*", "", first_line)  # "ì§ˆë¬¸:" ì œê±°
    cleaned = re.sub(r"<[^>]+>", "", cleaned)
    cleaned = re.sub(r"[\\\n\r\t]", " ", cleaned)
    cleaned = re.sub(r"\s+", " ", cleaned).strip()
    return [kw.strip() for kw in cleaned.split(",") if kw.strip()]


def call_vllm_summarize_article(data: dict, user_question: str = None):
    """
    ìŠ¤í† ë¦¬í…”ë§ ìš”ì•½ìš© LLM í˜¸ì¶œ í•¨ìˆ˜
    :param data: dict í˜•íƒœë¡œ ì „ë‹¬ëœ ì¥ì•  ë°ì´í„° (FastAPIì—ì„œ ê·¸ëŒ€ë¡œ ì „ë‹¬ë¨)
    :param user_question: ì„ íƒì  ì‚¬ìš©ì ì§ˆë¬¸ (ê¸°ì¡´ êµ¬ì¡° ìœ ì§€)
    """

    # ğŸ”¹ ë°ì´í„° ì •ë¦¬
    content = clean_article_text(data.get("content", ""))
    store_name = data.get("store_name", "")
    date = data.get("date", "")
    fault_major = data.get("fault_major", "")
    fault_mid = data.get("fault_mid", "")
    fault_minor = data.get("fault_minor", "")
    ocs_major = data.get("ocs_cause_major", "")
    ocs_mid = data.get("ocs_cause_mid", "")
    ocs_minor = data.get("ocs_cause_minor", "")
    department = data.get("department_main", "")
    urgency = data.get("urgency", "")

    # ğŸ”¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
ë‹¤ìŒì€ {store_name} ì í¬ì—ì„œ ë°œìƒí•œ ì¥ì•  ë‚´ì—­ì…ë‹ˆë‹¤.
í˜„ì¥ ì—”ì§€ë‹ˆì–´ê°€ ìƒê¸‰ ê´€ë¦¬ìì—ê²Œ êµ¬ë‘ë¡œ ë³´ê³ í•˜ë“¯, ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•œ ìŠ¤í† ë¦¬í…”ë§ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.

ì¡°ê±´:
- "ìš”ì•½"ì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
- ì„¸ ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±
- ì¥ì•  ë°œìƒ â†’ ì›ì¸ â†’ ì¡°ì¹˜/ê²°ê³¼ ìˆœì„œë¡œ ê¸°ìˆ 
- ê¸´ê¸‰ë„(A~C)ëŠ” ë¬¸ë§¥ì— ë…¹ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì˜í•  ê²ƒ
- ìˆ«ì, ì½”ë“œëª…(VKV47 ë“±)ì€ ì •í™•í•˜ê²Œ ìœ ì§€í•  ê²ƒ
- ì¥ì•  ì›ì¸ê³¼ ì²˜ë¦¬ ê²°ê³¼ë§Œ ê°„ê²°í•˜ê²Œ 2~3ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬
- ì‚¬ì‹¤ ê·¼ê±°ê°€ ì—†ëŠ” ì¶”ë¡  ë¬¸ì¥ì€ ì‘ì„±í•˜ì§€ ë§ ê²ƒ

ğŸ“… ë‚ ì§œ: {date}
ğŸª ì í¬ëª…: {store_name}
âš™ï¸ ì¥ì• ìœ í˜•: {fault_major} > {fault_mid} > {fault_minor}
ğŸ§© OCS ì›ì¸:
  - ëŒ€ë¶„ë¥˜: {ocs_major}
  - ì¤‘ë¶„ë¥˜: {ocs_mid}
  - ì†Œë¶„ë¥˜: {ocs_minor}
ğŸ¢ ì²˜ë¦¬ë¶€ì„œ: {department}
ğŸš¨ ê¸´ê¸‰ë„: {urgency}

[ë³¸ë¬¸]
{content}
"""

    # ğŸ”¸ vLLM í˜¸ì¶œ (max_tokensì€ ìƒí™©ì— ë§ê²Œ)
    raw_summary = call_vllm(prompt, max_tokens=1024)

    # ğŸ”¸ í›„ì²˜ë¦¬: ì˜ë¯¸ ìœ ì§€í•œ ë¬¸ì¥ ì •ë¦¬
    return clean_sentences_preserve_meaning(raw_summary)




# âœ… 5ï¸âƒ£ ë¬¸ì¥ ì •ì œ í•¨ìˆ˜
def clean_sentences_preserve_meaning(text: str) -> str:
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'[\r\n\t]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text


# âœ… 6ï¸âƒ£ ê¸°ì‚¬ ë³¸ë¬¸ ì •ì œ í•¨ìˆ˜
def clean_article_text(text: str) -> str:
    text = text.replace('\n', ' ').replace('\r', ' ')
    text = text.replace('â€œ', '"').replace('â€', '"')
    text = text.replace("â€˜", "'").replace("â€™", "'")
    text = re.sub(r"\([^)]{0,30}\)", "", text)
    text = re.sub(r"[â€¢â˜…â˜†â–¶â–²â–¼â†’â€»]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text
